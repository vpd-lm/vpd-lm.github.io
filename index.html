<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="VPD-LM: An end-to-end Vision-Language Model for Autonomous Driving using object-centric visual prompts and chain-of-thought reasoning for enhanced safety assessment, perception, and planning.">
  <meta property="og:title" content="VPD-LM: Improving Driving Safety Assessment via Object-Level Visual Prompting in Vision-Language Models"/>
  <meta property="og:description" content="VPD-LM addresses limitations in VLM-based autonomous driving by incorporating object-centric, video-based visual prompts and chain-of-thought reasoning to enhance safety, interpretability, and robustness."/>
  <meta property="og:url" content="YOUR_WEBSITE_URL_HERE"/>
  <meta property="og:image" content="static/image/vpd_lm_banner.png"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="VPD-LM: Improving Driving Safety Assessment via Object-Level Visual Prompting in Vision-Language Models">
  <meta name="twitter:description" content="VPD-LM addresses limitations in VLM-based autonomous driving by incorporating object-centric, video-based visual prompts and chain-of-thought reasoning to enhance safety, interpretability, and robustness.">
  <meta name="twitter:image" content="static/images/vpd_lm_twitter_banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Autonomous Driving, Vision-Language Models, Safety Assessment, Visual Prompting, Risk Assessment, VPD-LM, NeurIPS">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>VPD-LM: Driving Safety Assessment</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    /* Base font */
    body { font-size: 0.85rem; }

    /* Clear hierarchy */
    h1.title.is-1.publication-title { font-size: 2.3rem; }
    h2.title.is-3.has-text-centered { font-size: 1.8rem; margin-bottom: .6rem; }
    h3.subtitle.is-size-4-tablet    { font-size: 0.85rem; }
    h4.title.is-4.has-text-centered { font-size: 1.3rem; }

    /* Paragraph & code */
    p.is-size-5, .content p { font-size: 0.8rem; line-height: 1.35; }
    pre code                { font-size: 0.7rem; }

    /* Layout width */
    .container.is-max-desktop { max-width: 1200px; }

    hr.section-divider { margin: .4rem 0 1.2rem 0; border: none; height: 1px; background: #e0e0e0; }
    .results-carousel .item {
    margin: 5px;
    padding: 20px;
    height: auto !important;        /* let item stretch to fit text */
    overflow: visible;              /* ensure text isn’t clipped */
    font-size: initial;             /* re‑enable inherited font size */
  }
  </style>
</head>
<body>

<!-- ────────── HERO TITLE ────────── -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            VPD-LM: Improving Driving Safety Assessment via Object-Level Visual Prompting in Vision-Language Models
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Anonymous Author(s)</span>
          </div>
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <a href="VPD_LM (5).pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
            <span class="icon"><i class="ai ai-arxiv"></i></span><span>Paper PDF</span>
          </a>
          <a href="#" target="_blank" class="external-link button is-normal is-rounded is-dark">
            <span class="icon"><i class="fab fa-github"></i></span><span>Code (Coming Soon)</span>
          </a>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ────────── ABSTRACT ────────── -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="content has-text-justified">
        <h2 class="title is-3 has-text-centered">Abstract</h2>
        <hr class="section-divider">
        <p class="is-size-5">
          Vision-Language Models (VLMs) have demonstrated remarkable visual reasoning capabilities, positioning them as promising solutions for a wide range of autonomous driving (AD) tasks. Unlike traditional expert-driven AD models, which often operate as opaque black boxes, VLMs generate natural language explanations for their decisions, offering inherent interpretability. This interpretability enables explicit reasoning about driving safety and facilitates the identification of rare or high-risk scenarios that conventional systems may overlook. However, existing VLM-based frameworks often struggle with grounding and tracking specific objects over time—a limitation that undermines robust decision-making in dynamic, real-world environments.
          In this work, we introduce <em><b>VPD-LM</b></em>, an end-to-end Vision-Language Model for Autonomous Driving that addresses these challenges through object-centric, video-based visual prompts and chain-of-thought (CoT) reasoning. <em><b>VPD-LM</b></em> processes raw camera inputs and sensor metadata to generate interpretable natural language outputs for core driving tasks, including planning, perception, and safety assessment.
          To rigorously evaluate safety reasoning, we go beyond standard nuScenes-based benchmarks by constructing a novel Driving Safety Benchmark. We extract approximately 3,000 long-tail scenarios with potential collision risks from the larger nuPlan dataset using our proposed Road Graph Occupancy Detection method. From these, 600 representative scenarios are manually labeled into three risk categories—low, medium, and high—creating a challenging and fine-grained testbed for risk-aware driving models.
          Empirical results demonstrate that <em><b>VPD-LM</b></em> achieves strong performance in motion planning and threat assessment while generalizing effectively to complex and previously unseen scenarios. Our work highlights the potential of VLM-driven reasoning to significantly enhance safety, interpretability, and robustness in next-generation autonomous driving systems.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- ────────── OUR APPROACH ────────── -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Our Approach</h2>
      <hr class="section-divider">

      <div id="results-carousel-approach" class="carousel results-carousel" data-interval="4500">

        <!-- 1 -->
        <div class="item">
          <h3 class="subtitle is-size-4-tablet has-text-weight-bold has-text-centered has-background-info-light pt-3 pb-3">
            1. Object-Centric Visual Prompting &amp; Annotation
          </h3>
          <div class="columns is-vcentered">
            <div class="column is-one-third">
              <img src="static/images/vpd_lm_concept_visual_prompting.png" alt="Visual Prompting"
                   style="width:100%;border:1px solid #ccc;">
            </div>
            <div class="column">
              <p class="is-size-5">
                Detection models (e.g., DINO, YOLO-World) mark key road agents; SAM-2 tracks them across frames,
                producing masks and IDs that become visual prompts guiding the VLM’s attention.
              </p>
            </div>
          </div>
        </div>

        <!-- 2 -->
        <div class="item">
          <h3 class="subtitle is-size-4-tablet has-text-weight-bold has-text-centered has-background-info-light pt-3 pb-3">
            2. Mining Long-Tail Risky Scenarios
          </h3>
          <div class="columns is-vcentered">
            <div class="column is-one-third">
              <img src="static/images/vpd_lm_concept_risky_scenarios.png" alt="Risky Scenarios"
                   style="width:100%;border:1px solid #ccc;">
            </div>
            <div class="column">
              <p class="is-size-5">
                A rule-based Road-Graph Occupancy method simulates short-horizon actions; scenarios with overlapping
                occupancies are flagged as risky, forming our new benchmark.
              </p>
            </div>
          </div>
        </div>

        <!-- 3 -->
        <div class="item">
          <h3 class="subtitle is-size-4-tablet has-text-weight-bold has-text-centered has-background-info-light pt-3 pb-3">
            3. Structured Grounded Reasoning with VLMs
          </h3>
          <div class="columns is-vcentered">
            <div class="column is-one-third">
              <img src="static/images/vpd_lm_concept_reasoning_flow.png" alt="Reasoning Flow"
                   style="width:100%;border:1px solid #ccc;">
            </div>
            <div class="column">
              <p class="is-size-5">
                Hierarchical chain-of-thought: Scene → Crucial Objects → Task-specific module
                (Prediction / Planning / Risk Assessment), producing interpretable outputs.
              </p>
            </div>
          </div>
        </div>

      </div><!-- /carousel -->
    </div>
  </div>
</section>

<!-- ───────── DEMONSTRATION & RESULTS ───────── -->


  <section class="hero is-small" id="demonstration">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Demonstration &amp; Results</h2>
      <hr class="section-divider">

      <!-- Carousel with examples -->
      <div id="results-carousel-demos" class="carousel results-carousel" data-interval="6000">

        <!-- Example 1 -->
        <div class="item">
          <div class="box demo-example">
            <h4 class="title is-4 has-text-centered">Example&nbsp;1 • Residential Street Risk Assessment</h4>
            <div class="columns is-multiline is-mobile">
              <div class="column is-half"><figure class="image"><img src="static/examples/exp1/0229.jpg" alt="exp1 frame 1"></figure></div>
              <div class="column is-half"><figure class="image"><img src="static/examples/exp1/0231.jpg" alt="exp1 frame 2"></figure></div>
              <div class="column is-half"><figure class="image"><img src="static/examples/exp1/0233.jpg" alt="exp1 frame 3"></figure></div>
              <div class="column is-half"><figure class="image"><img src="static/examples/exp1/0237.jpg" alt="exp1 frame 4"></figure></div>
              <div class="column is-full">
<pre class="vlm-output"><strong>1. Scene Description</strong>
The scene depicts a clear, sunny day with excellent visibility on a residential street in what appears to be a suburban neighborhood. 
The ego vehicle is traveling on a two-lane road with yellow center dividing lines, passing through a curved section of the street. 
On both sides of the road are large, upscale houses with well-maintained properties featuring white fences, manicured lawns, and modern 
architecture. There are several parked vehicles along the curb, including a <strong>white pickup truck (object 1)</strong> on the right 
side and another <strong>white pickup truck (object 2)</strong> on the left side. The road surface shows some wear with visible cracks,
but overall it appears to be in reasonable condition. Trees line the street, and construction materials can be seen near one of the houses 
on the right side. <strong>Traffic appears light, with no moving vehicles visible ahead of the ego car.</strong>

<strong>2. Critical Objects</strong>
Object 1 — White pickup truck positioned front-right of the ego vehicle.
Object 2 — White pickup truck positioned front-left of the ego vehicle.

<strong>3. Risk Analysis</strong>
In this scenario, the ego vehicle is traveling on a residential street with moderate traffic conditions. The most significant risk factor 
is the proximity of multiple vehicles to the ego vehicle, particularly the white pickup trucks (objects 1 and 2) that are positioned to 
the front-right of the ego vehicle. These vehicles appear to be parked along the curb rather than actively participating in traffic flow.
If the ego vehicle were to make any sudden maneuvers, especially if attempting to change lanes or pass these parked vehicles, there would 
be a risk of collision. The vehicles are positioned close to each other, and any unexpected movement could create a dangerous situation. 
Additionally, the presence of parked vehicles on both sides of the road limits escape routes for the ego vehicle in case of an emergency stop.

<strong>Risk Level: UNSAFE</strong>
</pre>
              </div>
            </div>
          </div>
        </div>

        <!-- Example 2 -->
        <div class="item">
          <div class="box demo-example">
            <h4 class="title is-4 has-text-centered">Example&nbsp;2 • Urban Intersection with Pedestrian Crossing</h4>
            <div class="columns is-multiline is-mobile">
              <div class="column is-half"><figure class="image"><img src="static/examples/exp2/0209.jpg" alt="exp2 frame 1"></figure></div>
              <div class="column is-half"><figure class="image"><img src="static/examples/exp2/0211.jpg" alt="exp2 frame 2"></figure></div>
              <div class="column is-half"><figure class="image"><img src="static/examples/exp2/0215.jpg" alt="exp2 frame 3"></figure></div>
              <div class="column is-half"><figure class="image"><img src="static/examples/exp2/0217.jpg" alt="exp2 frame 4"></figure></div>
              <div class="column is-full">
<pre class="vlm-output"><strong>1. Scene Description</strong>
The scene depicts a clear, sunny day with excellent visibility on a residential street in what appears to be <strong>San&nbsp;Francisco</strong>,
characterized by its distinctive architecture. The ego vehicle is traveling on a two‑lane road with a yellow centerline dividing opposing 
traffic directions. The surrounding environment features multi‑story apartment buildings, single‑family homes, and commercial establishments.
Power lines run overhead along both sides of the street, and there are pedestrian crosswalks visible at an intersection ahead. The road surface
shows some wear with visible cracks, but overall appears to be in reasonable condition. The area has <strong>moderate traffic</strong> with 
several vehicles parked along the curb and a few moving vehicles visible in the distance. Trees lining the street and varied housing structures 
underscore the residential nature of the neighborhood.

<strong>2. Critical Objects</strong>
Object 1: this is a dark‑colored <strong>SUV/crossover</strong> vehicle positioned to the front‑right of the ego vehicle.
Object 2: this is a silver/gray <strong>sedan</strong> positioned further ahead and slightly to the right of the ego vehicle.
Object 3: this is a <strong>dark‑colored sedan/pickup truck</strong> parked on the left side of the road near a crosswalk.
Object 4: this appears to be a <strong>pedestrian crossing sign</strong> located near the crosswalk area on the left side of the road.

<strong>3. Risk Analysis</strong>
In this scenario, the ego vehicle is traveling on a two‑lane road approaching an intersection where it will likely need to stop for pedestrians 
crossing. The most critical objects are the <strong>dark SUV (object 1)</strong> directly ahead of the ego vehicle and the <strong>silver sedan (object 2)</strong> 
positioned to the right of the ego vehicle.

The dark SUV (object 1) presents no immediate conflict since it is positioned ahead of the ego vehicle and appears to be maintaining its lane. 
However, the silver sedan (object 2) could potentially enter the ego vehicle's path if making a right turn or changing lanes, creating a 
possible conflict that requires caution. The ego vehicle should maintain its current lane and slow down as it approaches the intersection, 
preparing to stop for pedestrians. Close monitoring of object 2’s intentions  is essential, while object 1 poses no immediate threat if it 
continues forward in its lane.

<strong>Risk Level: UNSAFE</strong></pre>
              </div>
            </div>
          </div>
        </div>

      </div><!-- /carousel -->

    </div>
  </div>
</section>







<!-- ────────── BIBTEX ────────── -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <hr class="section-divider">
<pre><code>@inproceedings{vpd_lm_neurips2025,
  title  = {Improving Driving Safety Assessment via Object-Level Visual Prompting in Vision-Language Models},
  author = {Anonymous Author(s)},
  booktitle = {Submitted to Conference on Neural Information Processing Systems (NeurIPS)},
  year   = {2025}
}</code></pre>
  </div>
</section>

<!-- ────────── FOOTER ────────── -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="color:gray;font-size:9.9px;">
            Page built with
            <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">
              Academic Project Page Template
            </a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
  /* Optional highlight helper (legacy) */
  function toggleHighlight(tag, color) {
    const tgt = event.target;
    const els = document.querySelectorAll('.' + tag);
    const active = tgt.classList.contains('highlight');
    document.querySelectorAll('.highlight').forEach(e => e.classList.remove('highlight'));
    if (!active) {
      tgt.classList.add('highlight');
      els.forEach(e => e.style.backgroundColor = color);
    } else {
      els.forEach(e => e.style.backgroundColor = '');
    }
  }
</script>
</body>
</html>
